{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data with sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('E:\\\\IIT Kanpur\\\\Placements\\\\Projects\\\\Amazon Fine Food Reviews\\\\Dataset\\\\database.sqlite') \n",
    "\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3\"\"\", con) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in our data (525814, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "print(\"Number of data points in our data\", filtered_data.shape)\n",
    "filtered_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364173, 10)\n",
      "69.25890143662969\n"
     ]
    }
   ],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "print(final.shape)\n",
    "\n",
    "#Checking to see how much % of data still remains\n",
    "print((final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    307061\n",
       "0     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "\n",
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                  ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "138706                     0                       0      1   939340800   \n",
       "138688                     1                       1      1  1194739200   \n",
       "138689                     1                       1      1  1191456000   \n",
       "138690                     1                       1      1  1076025600   \n",
       "138691                     3                       4      1  1018396800   \n",
       "\n",
       "                                           Summary  \\\n",
       "138706                   EVERY book is educational   \n",
       "138688  Love the book, miss the hard cover version   \n",
       "138689               chicken soup with rice months   \n",
       "138690      a good swingy rhythm for reading aloud   \n",
       "138691             A great way to learn the months   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  \n",
       "138690  This is a great little book to read aloud- it ...  \n",
       "138691  This is a book of poetry about the months of t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading W2V_TF-IDF matrix previously saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_tfidf = pd.read_csv(\"E:\\\\IIT Kanpur\\\\Placements\\\\Projects\\\\Amazon Fine Food Reviews\\\\w2v_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_tfidf.drop(w2v_tfidf.columns[[0]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray(final['Score'])\n",
    "print(np.count_nonzero(np.isnan(a)))\n",
    "\n",
    "w2v_tfidf['Score'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray(final['Time'])\n",
    "print(np.count_nonzero(np.isnan(a)))\n",
    "\n",
    "w2v_tfidf['TimeStamp'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Smapling 5% from the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "rand_ind = np.random.choice(w2v_tfidf.shape[0], int(0.05 * w2v_tfidf.shape[0]), replace=False)\n",
    "\n",
    "w2v_tfidf_rand = np.asarray(w2v_tfidf)[rand_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "Y_train_df = pd.DataFrame(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273537\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.365    \n",
      "Dependent Variable: 0.0000           AIC:              8068.6781\n",
      "Date:               2020-07-10 14:05 BIC:              8448.0003\n",
      "No. Observations:   14566            Log-Likelihood:   -3984.3  \n",
      "Df Model:           49               LL-Null:          -6277.5  \n",
      "Df Residuals:       14516            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     8.0000                                      \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0        1.1086     0.0771    14.3756   0.0000    0.9575    1.2598\n",
      "1       -0.5107     0.0711    -7.1869   0.0000   -0.6500   -0.3714\n",
      "2        1.3248     0.0754    17.5677   0.0000    1.1770    1.4726\n",
      "3       -0.5267     0.0758    -6.9448   0.0000   -0.6753   -0.3780\n",
      "4        0.6201     0.0655     9.4609   0.0000    0.4916    0.7485\n",
      "5       -0.4240     0.0658    -6.4469   0.0000   -0.5529   -0.2951\n",
      "6       -0.5326     0.0585    -9.0981   0.0000   -0.6473   -0.4178\n",
      "7       -0.7628     0.0650   -11.7413   0.0000   -0.8902   -0.6355\n",
      "8       -0.6883     0.0646   -10.6597   0.0000   -0.8149   -0.5618\n",
      "9        0.1010     0.0715     1.4135   0.1575   -0.0391    0.2411\n",
      "10      -0.3195     0.0718    -4.4478   0.0000   -0.4603   -0.1787\n",
      "11       0.0983     0.0725     1.3568   0.1749   -0.0437    0.2403\n",
      "12      -0.0638     0.0707    -0.9026   0.3668   -0.2023    0.0747\n",
      "13       0.2503     0.0672     3.7245   0.0002    0.1186    0.3819\n",
      "14      -0.3306     0.0688    -4.8041   0.0000   -0.4654   -0.1957\n",
      "15       1.0497     0.0738    14.2188   0.0000    0.9050    1.1944\n",
      "16       0.2103     0.0662     3.1778   0.0015    0.0806    0.3401\n",
      "17       0.3518     0.0630     5.5841   0.0000    0.2283    0.4752\n",
      "18       1.3713     0.0684    20.0497   0.0000    1.2372    1.5053\n",
      "19      -0.4876     0.0566    -8.6088   0.0000   -0.5986   -0.3766\n",
      "20      -0.4937     0.0640    -7.7122   0.0000   -0.6191   -0.3682\n",
      "21       0.1697     0.0599     2.8323   0.0046    0.0523    0.2872\n",
      "22       0.4370     0.0731     5.9743   0.0000    0.2936    0.5803\n",
      "23      -0.9656     0.0809   -11.9408   0.0000   -1.1241   -0.8071\n",
      "24      -0.3112     0.0801    -3.8854   0.0001   -0.4681   -0.1542\n",
      "25       0.4889     0.0616     7.9389   0.0000    0.3682    0.6096\n",
      "26       1.1053     0.0864    12.7903   0.0000    0.9359    1.2747\n",
      "27       0.4164     0.0621     6.7085   0.0000    0.2948    0.5381\n",
      "28       0.7296     0.0756     9.6554   0.0000    0.5815    0.8777\n",
      "29      -0.2600     0.0622    -4.1805   0.0000   -0.3819   -0.1381\n",
      "30       0.3119     0.0725     4.3019   0.0000    0.1698    0.4540\n",
      "31       0.4049     0.0644     6.2879   0.0000    0.2787    0.5311\n",
      "32      -0.4470     0.0643    -6.9487   0.0000   -0.5730   -0.3209\n",
      "33      -0.7719     0.0627   -12.3095   0.0000   -0.8948   -0.6490\n",
      "34      -0.6787     0.0680    -9.9852   0.0000   -0.8120   -0.5455\n",
      "35      -0.7810     0.0731   -10.6828   0.0000   -0.9243   -0.6377\n",
      "36       0.8229     0.0685    12.0072   0.0000    0.6886    0.9572\n",
      "37      -0.1982     0.0678    -2.9235   0.0035   -0.3311   -0.0653\n",
      "38      -0.0659     0.0607    -1.0850   0.2779   -0.1849    0.0531\n",
      "39      -0.3702     0.0684    -5.4086   0.0000   -0.5043   -0.2360\n",
      "40      -0.4767     0.0514    -9.2729   0.0000   -0.5775   -0.3760\n",
      "41      -0.9198     0.0678   -13.5728   0.0000   -1.0526   -0.7870\n",
      "42      -1.1166     0.0654   -17.0783   0.0000   -1.2447   -0.9884\n",
      "43      -0.8087     0.0715   -11.3103   0.0000   -0.9489   -0.6686\n",
      "44      -0.5877     0.0707    -8.3174   0.0000   -0.7262   -0.4492\n",
      "45      -0.0779     0.0674    -1.1558   0.2477   -0.2101    0.0542\n",
      "46       0.1890     0.0681     2.7741   0.0055    0.0555    0.3226\n",
      "47      -0.0988     0.0665    -1.4853   0.1375   -0.2293    0.0316\n",
      "48       1.0772     0.0709    15.1953   0.0000    0.9383    1.2162\n",
      "49       0.3654     0.0700     5.2188   0.0000    0.2282    0.5026\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "logit_model = sm.Logit(Y_train_df, X_train_df)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14566, 44)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [9, 11,12,38,45,47]\n",
    "X_train_df.drop(X_train_df.columns[a], axis = 1, inplace = True)\n",
    "X_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273846\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.365    \n",
      "Dependent Variable: 0.0000           AIC:              8065.6719\n",
      "Date:               2020-07-10 14:07 BIC:              8399.4755\n",
      "No. Observations:   14566            Log-Likelihood:   -3988.8  \n",
      "Df Model:           43               LL-Null:          -6277.5  \n",
      "Df Residuals:       14522            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     8.0000                                      \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0        1.0314     0.0713    14.4678   0.0000    0.8917    1.1711\n",
      "1       -0.4864     0.0698    -6.9670   0.0000   -0.6233   -0.3496\n",
      "2        1.3126     0.0730    17.9880   0.0000    1.1695    1.4556\n",
      "3       -0.4908     0.0712    -6.8899   0.0000   -0.6305   -0.3512\n",
      "4        0.6109     0.0641     9.5270   0.0000    0.4852    0.7365\n",
      "5       -0.4174     0.0610    -6.8404   0.0000   -0.5370   -0.2978\n",
      "6       -0.5742     0.0531   -10.8222   0.0000   -0.6782   -0.4702\n",
      "7       -0.7491     0.0636   -11.7877   0.0000   -0.8737   -0.6246\n",
      "8       -0.6914     0.0629   -10.9853   0.0000   -0.8147   -0.5680\n",
      "10      -0.3256     0.0703    -4.6338   0.0000   -0.4633   -0.1879\n",
      "13       0.1977     0.0616     3.2074   0.0013    0.0769    0.3185\n",
      "14      -0.3047     0.0630    -4.8390   0.0000   -0.4281   -0.1813\n",
      "15       1.0374     0.0706    14.6953   0.0000    0.8990    1.1757\n",
      "16       0.1930     0.0657     2.9353   0.0033    0.0641    0.3218\n",
      "17       0.3600     0.0611     5.8876   0.0000    0.2401    0.4798\n",
      "18       1.3387     0.0640    20.9044   0.0000    1.2132    1.4643\n",
      "19      -0.5088     0.0554    -9.1860   0.0000   -0.6173   -0.4002\n",
      "20      -0.5023     0.0635    -7.9099   0.0000   -0.6268   -0.3779\n",
      "21       0.1480     0.0573     2.5824   0.0098    0.0357    0.2603\n",
      "22       0.4345     0.0686     6.3386   0.0000    0.3002    0.5689\n",
      "23      -0.9029     0.0725   -12.4528   0.0000   -1.0450   -0.7608\n",
      "24      -0.2905     0.0760    -3.8198   0.0001   -0.4395   -0.1414\n",
      "25       0.5030     0.0602     8.3611   0.0000    0.3851    0.6209\n",
      "26       1.0175     0.0792    12.8424   0.0000    0.8622    1.1728\n",
      "27       0.4323     0.0594     7.2795   0.0000    0.3159    0.5487\n",
      "28       0.6993     0.0734     9.5204   0.0000    0.5553    0.8432\n",
      "29      -0.2791     0.0537    -5.1936   0.0000   -0.3844   -0.1738\n",
      "30       0.3044     0.0693     4.3926   0.0000    0.1686    0.4403\n",
      "31       0.4512     0.0609     7.4039   0.0000    0.3318    0.5707\n",
      "32      -0.4236     0.0603    -7.0304   0.0000   -0.5417   -0.3055\n",
      "33      -0.7242     0.0589   -12.2885   0.0000   -0.8397   -0.6087\n",
      "34      -0.6919     0.0657   -10.5303   0.0000   -0.8207   -0.5631\n",
      "35      -0.8155     0.0713   -11.4399   0.0000   -0.9552   -0.6758\n",
      "36       0.8023     0.0665    12.0687   0.0000    0.6720    0.9326\n",
      "37      -0.1551     0.0648    -2.3921   0.0168   -0.2821   -0.0280\n",
      "39      -0.3583     0.0659    -5.4361   0.0000   -0.4875   -0.2291\n",
      "40      -0.4699     0.0502    -9.3617   0.0000   -0.5683   -0.3715\n",
      "41      -0.8861     0.0662   -13.3859   0.0000   -1.0158   -0.7563\n",
      "42      -1.0854     0.0577   -18.7957   0.0000   -1.1986   -0.9722\n",
      "43      -0.7930     0.0698   -11.3674   0.0000   -0.9297   -0.6563\n",
      "44      -0.5740     0.0698    -8.2276   0.0000   -0.7107   -0.4372\n",
      "46       0.2218     0.0661     3.3568   0.0008    0.0923    0.3513\n",
      "48       1.0960     0.0655    16.7345   0.0000    0.9676    1.2243\n",
      "49       0.3405     0.0684     4.9759   0.0000    0.2064    0.4746\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(Y_train_df, X_train_df)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_df, Y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3642, 44)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df = pd.DataFrame(X_test)\n",
    "final_cols = X_train_df.columns\n",
    "final_cols = list(final_cols)\n",
    "X_test_df = X_test_df.iloc[:, final_cols]\n",
    "X_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3642,), (3642, 1))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 261  329]\n",
      " [ 108 2944]]\n",
      "0.9646133682830931 0.8994805988389857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.44      0.54       590\n",
      "         1.0       0.90      0.96      0.93      3052\n",
      "\n",
      "    accuracy                           0.88      3642\n",
      "   macro avg       0.80      0.70      0.74      3642\n",
      "weighted avg       0.87      0.88      0.87      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "https://github.com/WillKoehrsen/Machine-Learning-Projects/blob/master/Random%20Forest%20Tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators =100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(Y_test, y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the parameters, best fit randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                                           11, 12, 12, 12, 12, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': array([ 10,  13,  17,  21,  25,  29,  33,  37,  41,  44,  48,  52,  56,\n",
       "        60,  64,  68,  72,  75,  79,  83,  87,  91,  95,  99, 103, 106,\n",
       "       110, 114, 118, 122, 126, 130, 134, 137, 141, 145, 149, 153, 157,\n",
       "       161, 165, 168, 172, 176, 180, 184, 188, 192, 196, 200])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=0)\n",
    "\n",
    "# Fit \n",
    "rs.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 192,\n",
       " 'min_samples_split': 5,\n",
       " 'max_leaf_nodes': 15,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 11,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_value = roc_auc_score(Y_test, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  32  558]\n",
      " [   6 3046]]\n",
      "****************************************************************************************************\n",
      "0.9980340760157274 0.8451720310765816\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.05      0.10       590\n",
      "         1.0       0.85      1.00      0.92      3052\n",
      "\n",
      "    accuracy                           0.85      3642\n",
      "   macro avg       0.84      0.53      0.51      3642\n",
      "weighted avg       0.84      0.85      0.78      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='linear') \n",
    "  \n",
    "# fitting x samples and y classes \n",
    "clf.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 231  359]\n",
      " [  77 2975]]\n",
      "****************************************************************************************************\n",
      "0.9747706422018348 0.8923215356928614\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.39      0.51       590\n",
      "         1.0       0.89      0.97      0.93      3052\n",
      "\n",
      "    accuracy                           0.88      3642\n",
      "   macro avg       0.82      0.68      0.72      3642\n",
      "weighted avg       0.87      0.88      0.86      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes\n",
    "https://towardsdatascience.com/implementing-naive-bayes-in-2-minutes-with-python-3ecd788803fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 332  258]\n",
      " [ 312 2740]]\n",
      "****************************************************************************************************\n",
      "0.8977719528178244 0.9139426284189459\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.56      0.54       590\n",
      "         1.0       0.91      0.90      0.91      3052\n",
      "\n",
      "    accuracy                           0.84      3642\n",
      "   macro avg       0.71      0.73      0.72      3642\n",
      "weighted avg       0.85      0.84      0.85      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "https://medium.com/datadriveninvestor/building-neural-network-using-keras-for-classification-3a3656c726c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal', input_dim = 50))\n",
    "\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam', loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "14566/14566 [==============================] - 2s 171us/step - loss: 0.3612 - accuracy: 0.8597\n",
      "Epoch 2/100\n",
      "14566/14566 [==============================] - 2s 127us/step - loss: 0.2790 - accuracy: 0.8884\n",
      "Epoch 3/100\n",
      "14566/14566 [==============================] - 2s 125us/step - loss: 0.2742 - accuracy: 0.8880\n",
      "Epoch 4/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2715 - accuracy: 0.8908\n",
      "Epoch 5/100\n",
      "14566/14566 [==============================] - 2s 127us/step - loss: 0.2686 - accuracy: 0.8908\n",
      "Epoch 6/100\n",
      "14566/14566 [==============================] - 2s 126us/step - loss: 0.2660 - accuracy: 0.8917\n",
      "Epoch 7/100\n",
      "14566/14566 [==============================] - 2s 127us/step - loss: 0.2642 - accuracy: 0.8927\n",
      "Epoch 8/100\n",
      "14566/14566 [==============================] - 2s 125us/step - loss: 0.2625 - accuracy: 0.8928\n",
      "Epoch 9/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2614 - accuracy: 0.8952\n",
      "Epoch 10/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2602 - accuracy: 0.8962\n",
      "Epoch 11/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2589 - accuracy: 0.8952\n",
      "Epoch 12/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2576 - accuracy: 0.8959\n",
      "Epoch 13/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2568 - accuracy: 0.8959\n",
      "Epoch 14/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2558 - accuracy: 0.8964\n",
      "Epoch 15/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2549 - accuracy: 0.8973\n",
      "Epoch 16/100\n",
      "14566/14566 [==============================] - 2s 125us/step - loss: 0.2537 - accuracy: 0.8975\n",
      "Epoch 17/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2529 - accuracy: 0.8984\n",
      "Epoch 18/100\n",
      "14566/14566 [==============================] - 2s 124us/step - loss: 0.2520 - accuracy: 0.8987\n",
      "Epoch 19/100\n",
      "14566/14566 [==============================] - 2s 125us/step - loss: 0.2508 - accuracy: 0.8992\n",
      "Epoch 20/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2504 - accuracy: 0.8993\n",
      "Epoch 21/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2502 - accuracy: 0.90130s - loss: 0.2480 - accuracy - ETA: 0s - loss: 0.2502 - accuracy\n",
      "Epoch 22/100\n",
      "14566/14566 [==============================] - 2s 124us/step - loss: 0.2488 - accuracy: 0.9005\n",
      "Epoch 23/100\n",
      "14566/14566 [==============================] - 2s 126us/step - loss: 0.2482 - accuracy: 0.9013\n",
      "Epoch 24/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2473 - accuracy: 0.9011\n",
      "Epoch 25/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2468 - accuracy: 0.9006\n",
      "Epoch 26/100\n",
      "14566/14566 [==============================] - 2s 130us/step - loss: 0.2464 - accuracy: 0.9002\n",
      "Epoch 27/100\n",
      "14566/14566 [==============================] - 2s 126us/step - loss: 0.2456 - accuracy: 0.9010\n",
      "Epoch 28/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2452 - accuracy: 0.9020\n",
      "Epoch 29/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2448 - accuracy: 0.9020\n",
      "Epoch 30/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2445 - accuracy: 0.9014\n",
      "Epoch 31/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2438 - accuracy: 0.9026\n",
      "Epoch 32/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2434 - accuracy: 0.9035\n",
      "Epoch 33/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2423 - accuracy: 0.9029\n",
      "Epoch 34/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2426 - accuracy: 0.9030\n",
      "Epoch 35/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2424 - accuracy: 0.9028\n",
      "Epoch 36/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2416 - accuracy: 0.9033\n",
      "Epoch 37/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2411 - accuracy: 0.9048\n",
      "Epoch 38/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2407 - accuracy: 0.9027\n",
      "Epoch 39/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2402 - accuracy: 0.9050\n",
      "Epoch 40/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2405 - accuracy: 0.9042\n",
      "Epoch 41/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2391 - accuracy: 0.9048\n",
      "Epoch 42/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2385 - accuracy: 0.9044\n",
      "Epoch 43/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2378 - accuracy: 0.9054\n",
      "Epoch 44/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2383 - accuracy: 0.9056\n",
      "Epoch 45/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2376 - accuracy: 0.9042\n",
      "Epoch 46/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2369 - accuracy: 0.9069\n",
      "Epoch 47/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2371 - accuracy: 0.9046\n",
      "Epoch 48/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2360 - accuracy: 0.9059\n",
      "Epoch 49/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2359 - accuracy: 0.9051\n",
      "Epoch 50/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2354 - accuracy: 0.9062\n",
      "Epoch 51/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2357 - accuracy: 0.9057\n",
      "Epoch 52/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2343 - accuracy: 0.9053\n",
      "Epoch 53/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2344 - accuracy: 0.9064\n",
      "Epoch 54/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2342 - accuracy: 0.9062\n",
      "Epoch 55/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2326 - accuracy: 0.9062\n",
      "Epoch 56/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2326 - accuracy: 0.9076\n",
      "Epoch 57/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2324 - accuracy: 0.9070\n",
      "Epoch 58/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2320 - accuracy: 0.9070\n",
      "Epoch 59/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2318 - accuracy: 0.9072\n",
      "Epoch 60/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2306 - accuracy: 0.9070\n",
      "Epoch 61/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2307 - accuracy: 0.9064\n",
      "Epoch 62/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2301 - accuracy: 0.9089\n",
      "Epoch 63/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2298 - accuracy: 0.9079\n",
      "Epoch 64/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2299 - accuracy: 0.9083\n",
      "Epoch 65/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2288 - accuracy: 0.9091\n",
      "Epoch 66/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2285 - accuracy: 0.9080\n",
      "Epoch 67/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2286 - accuracy: 0.9076\n",
      "Epoch 68/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2286 - accuracy: 0.9069\n",
      "Epoch 69/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2272 - accuracy: 0.9086\n",
      "Epoch 70/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2273 - accuracy: 0.9092\n",
      "Epoch 71/100\n",
      "14566/14566 [==============================] - 2s 118us/step - loss: 0.2277 - accuracy: 0.9086\n",
      "Epoch 72/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2263 - accuracy: 0.9083\n",
      "Epoch 73/100\n",
      "14566/14566 [==============================] - 2s 124us/step - loss: 0.2266 - accuracy: 0.9096\n",
      "Epoch 74/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2262 - accuracy: 0.9095\n",
      "Epoch 75/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2256 - accuracy: 0.9094\n",
      "Epoch 76/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2251 - accuracy: 0.9092\n",
      "Epoch 77/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2247 - accuracy: 0.9094\n",
      "Epoch 78/100\n",
      "14566/14566 [==============================] - 2s 119us/step - loss: 0.2243 - accuracy: 0.9099\n",
      "Epoch 79/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2241 - accuracy: 0.9106\n",
      "Epoch 80/100\n",
      "14566/14566 [==============================] - 2s 124us/step - loss: 0.2234 - accuracy: 0.9108\n",
      "Epoch 81/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2234 - accuracy: 0.9110\n",
      "Epoch 82/100\n",
      "14566/14566 [==============================] - 2s 118us/step - loss: 0.2236 - accuracy: 0.9085\n",
      "Epoch 83/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2228 - accuracy: 0.9097\n",
      "Epoch 84/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2218 - accuracy: 0.9104\n",
      "Epoch 85/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2224 - accuracy: 0.9110\n",
      "Epoch 86/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2221 - accuracy: 0.9114\n",
      "Epoch 87/100\n",
      "14566/14566 [==============================] - 2s 123us/step - loss: 0.2218 - accuracy: 0.9098\n",
      "Epoch 88/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2216 - accuracy: 0.9110\n",
      "Epoch 89/100\n",
      "14566/14566 [==============================] - 2s 118us/step - loss: 0.2209 - accuracy: 0.9116\n",
      "Epoch 90/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2209 - accuracy: 0.9105\n",
      "Epoch 91/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2201 - accuracy: 0.9125\n",
      "Epoch 92/100\n",
      "14566/14566 [==============================] - 2s 128us/step - loss: 0.2196 - accuracy: 0.9122\n",
      "Epoch 93/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2205 - accuracy: 0.9101\n",
      "Epoch 94/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2198 - accuracy: 0.9129\n",
      "Epoch 95/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2195 - accuracy: 0.9116\n",
      "Epoch 96/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2203 - accuracy: 0.9106\n",
      "Epoch 97/100\n",
      "14566/14566 [==============================] - 2s 120us/step - loss: 0.2190 - accuracy: 0.9115\n",
      "Epoch 98/100\n",
      "14566/14566 [==============================] - 2s 127us/step - loss: 0.2189 - accuracy: 0.9123\n",
      "Epoch 99/100\n",
      "14566/14566 [==============================] - 2s 122us/step - loss: 0.2187 - accuracy: 0.9128\n",
      "Epoch 100/100\n",
      "14566/14566 [==============================] - 2s 121us/step - loss: 0.2189 - accuracy: 0.9134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1cbafb39dc8>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train, Y_train, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14566/14566 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21226350829919813, 0.9146642684936523]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, Y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 299  291]\n",
      " [ 139 2913]]\n",
      "****************************************************************************************************\n",
      "0.9544560943643512 0.9091760299625468\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.51      0.58       590\n",
      "         1.0       0.91      0.95      0.93      3052\n",
      "\n",
      "    accuracy                           0.88      3642\n",
      "   macro avg       0.80      0.73      0.76      3642\n",
      "weighted avg       0.87      0.88      0.87      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors\n",
    "https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best is for k = 10 tried with other values but best is k = 10\n",
    "model = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 181  409]\n",
      " [  84 2968]]\n",
      "****************************************************************************************************\n",
      "0.9724770642201835 0.8788865857269766\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.31      0.42       590\n",
      "         1.0       0.88      0.97      0.92      3052\n",
      "\n",
      "    accuracy                           0.86      3642\n",
      "   macro avg       0.78      0.64      0.67      3642\n",
      "weighted avg       0.85      0.86      0.84      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
