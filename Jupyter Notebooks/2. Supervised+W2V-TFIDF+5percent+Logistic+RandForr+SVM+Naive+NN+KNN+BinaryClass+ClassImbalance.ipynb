{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data with sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('E:\\\\IIT Kanpur\\\\Placements\\\\Projects\\\\Amazon Fine Food Reviews\\\\Dataset\\\\database.sqlite') \n",
    "\n",
    "filtered_data = pd.read_sql_query(\"\"\" SELECT * FROM Reviews WHERE Score != 3\"\"\", con) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in our data (525814, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "print(\"Number of data points in our data\", filtered_data.shape)\n",
    "filtered_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364173, 10)\n",
      "69.25890143662969\n"
     ]
    }
   ],
   "source": [
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "print(final.shape)\n",
    "\n",
    "#Checking to see how much % of data still remains\n",
    "print((final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364171, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    307061\n",
       "0     57110\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "\n",
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                  ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "138706                     0                       0      1   939340800   \n",
       "138688                     1                       1      1  1194739200   \n",
       "138689                     1                       1      1  1191456000   \n",
       "138690                     1                       1      1  1076025600   \n",
       "138691                     3                       4      1  1018396800   \n",
       "\n",
       "                                           Summary  \\\n",
       "138706                   EVERY book is educational   \n",
       "138688  Love the book, miss the hard cover version   \n",
       "138689               chicken soup with rice months   \n",
       "138690      a good swingy rhythm for reading aloud   \n",
       "138691             A great way to learn the months   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  \n",
       "138690  This is a great little book to read aloud- it ...  \n",
       "138691  This is a book of poetry about the months of t...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading W2V_TF-IDF matrix previously saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_tfidf = pd.read_csv(\"E:\\\\IIT Kanpur\\\\Placements\\\\Projects\\\\Amazon Fine Food Reviews\\\\w2v_tfidf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_tfidf.drop(w2v_tfidf.columns[[0]], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray(final['Score'])\n",
    "print(np.count_nonzero(np.isnan(a)))\n",
    "\n",
    "w2v_tfidf['Score'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray(final['Time'])\n",
    "print(np.count_nonzero(np.isnan(a)))\n",
    "\n",
    "w2v_tfidf['TimeStamp'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Smapling 5% from the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "rand_ind = np.random.choice(w2v_tfidf.shape[0], int(0.05 * w2v_tfidf.shape[0]), replace=False)\n",
    "\n",
    "w2v_tfidf_rand = np.asarray(w2v_tfidf)[rand_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split in ratio 80 : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14566, 50) (3642, 50) (14566, 1) (3642, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = w2v_tfidf_rand[:, :50]\n",
    "Y = w2v_tfidf_rand[:, 50:51]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Class imbalance Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.564001</td>\n",
       "      <td>-0.058113</td>\n",
       "      <td>0.601339</td>\n",
       "      <td>-0.281035</td>\n",
       "      <td>-0.119473</td>\n",
       "      <td>0.153355</td>\n",
       "      <td>-0.216625</td>\n",
       "      <td>-0.148660</td>\n",
       "      <td>-0.636599</td>\n",
       "      <td>-0.743581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>-1.075412</td>\n",
       "      <td>-1.332488</td>\n",
       "      <td>-0.347399</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.594633</td>\n",
       "      <td>-0.358533</td>\n",
       "      <td>0.210341</td>\n",
       "      <td>-0.608107</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.067735</td>\n",
       "      <td>-0.904856</td>\n",
       "      <td>0.934154</td>\n",
       "      <td>-0.464753</td>\n",
       "      <td>0.546090</td>\n",
       "      <td>-0.037378</td>\n",
       "      <td>0.345049</td>\n",
       "      <td>0.578616</td>\n",
       "      <td>-0.511612</td>\n",
       "      <td>-0.055142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655825</td>\n",
       "      <td>-1.932175</td>\n",
       "      <td>-0.007415</td>\n",
       "      <td>-0.630967</td>\n",
       "      <td>0.237394</td>\n",
       "      <td>1.608986</td>\n",
       "      <td>2.027691</td>\n",
       "      <td>-0.564050</td>\n",
       "      <td>-1.300743</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.412715</td>\n",
       "      <td>-1.131648</td>\n",
       "      <td>-0.121621</td>\n",
       "      <td>0.309196</td>\n",
       "      <td>0.712931</td>\n",
       "      <td>-0.078577</td>\n",
       "      <td>1.580521</td>\n",
       "      <td>-0.021504</td>\n",
       "      <td>-1.155676</td>\n",
       "      <td>-1.020775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039613</td>\n",
       "      <td>0.215575</td>\n",
       "      <td>-1.887987</td>\n",
       "      <td>-0.873798</td>\n",
       "      <td>0.208267</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>0.176566</td>\n",
       "      <td>0.518347</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.319674</td>\n",
       "      <td>-0.216596</td>\n",
       "      <td>0.278472</td>\n",
       "      <td>-0.388042</td>\n",
       "      <td>0.449741</td>\n",
       "      <td>-0.805975</td>\n",
       "      <td>0.459316</td>\n",
       "      <td>-0.469995</td>\n",
       "      <td>-0.305820</td>\n",
       "      <td>-0.508212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072224</td>\n",
       "      <td>-0.453960</td>\n",
       "      <td>-0.446523</td>\n",
       "      <td>-0.469024</td>\n",
       "      <td>-0.051081</td>\n",
       "      <td>0.436374</td>\n",
       "      <td>-0.067353</td>\n",
       "      <td>-0.320455</td>\n",
       "      <td>-0.445937</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469712</td>\n",
       "      <td>0.157217</td>\n",
       "      <td>-0.681802</td>\n",
       "      <td>-1.111380</td>\n",
       "      <td>0.397916</td>\n",
       "      <td>0.108865</td>\n",
       "      <td>-1.140457</td>\n",
       "      <td>-0.392039</td>\n",
       "      <td>-0.757706</td>\n",
       "      <td>-0.878586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.711121</td>\n",
       "      <td>-0.813196</td>\n",
       "      <td>0.405295</td>\n",
       "      <td>-0.381188</td>\n",
       "      <td>0.636632</td>\n",
       "      <td>0.171218</td>\n",
       "      <td>1.058547</td>\n",
       "      <td>0.170746</td>\n",
       "      <td>0.770526</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.564001 -0.058113  0.601339 -0.281035 -0.119473  0.153355 -0.216625   \n",
       "1  2.067735 -0.904856  0.934154 -0.464753  0.546090 -0.037378  0.345049   \n",
       "2 -0.412715 -1.131648 -0.121621  0.309196  0.712931 -0.078577  1.580521   \n",
       "3 -0.319674 -0.216596  0.278472 -0.388042  0.449741 -0.805975  0.459316   \n",
       "4  0.469712  0.157217 -0.681802 -1.111380  0.397916  0.108865 -1.140457   \n",
       "\n",
       "          7         8         9  ...        41        42        43        44  \\\n",
       "0 -0.148660 -0.636599 -0.743581  ...  0.532462 -1.075412 -1.332488 -0.347399   \n",
       "1  0.578616 -0.511612 -0.055142  ...  0.655825 -1.932175 -0.007415 -0.630967   \n",
       "2 -0.021504 -1.155676 -1.020775  ... -0.039613  0.215575 -1.887987 -0.873798   \n",
       "3 -0.469995 -0.305820 -0.508212  ...  0.072224 -0.453960 -0.446523 -0.469024   \n",
       "4 -0.392039 -0.757706 -0.878586  ... -0.711121 -0.813196  0.405295 -0.381188   \n",
       "\n",
       "         45        46        47        48        49    y  \n",
       "0  0.593220  0.594633 -0.358533  0.210341 -0.608107  1.0  \n",
       "1  0.237394  1.608986  2.027691 -0.564050 -1.300743  1.0  \n",
       "2  0.208267  0.023842  0.176566  0.518347  0.016671  1.0  \n",
       "3 -0.051081  0.436374 -0.067353 -0.320455 -0.445937  1.0  \n",
       "4  0.636632  0.171218  1.058547  0.170746  0.770526  1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(X_train)\n",
    "data['y'] = Y_train\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    12311\n",
       "0.0     2255\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "sns.countplot(x = 'y', data=data, palette = 'hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling class imbalance problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y_1 = data[data['y'] == 1.]\n",
    "data_y_0 = data[data['y'] == 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y_1 = data_y_1.sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y_1_trunc = data_y_1.iloc[:2255, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_df = [data_y_0, data_y_1_trunc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.concat(both_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 51)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_final.sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2255\n",
       "0.0    2255\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.405216\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.415    \n",
      "Dependent Variable: y                AIC:              3755.0481\n",
      "Date:               2020-07-10 12:48 BIC:              4075.7507\n",
      "No. Observations:   4510             Log-Likelihood:   -1827.5  \n",
      "Df Model:           49               LL-Null:          -3126.1  \n",
      "Df Residuals:       4460             LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     7.0000                                      \n",
      "------------------------------------------------------------------\n",
      "          Coef.    Std.Err.      z      P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0         0.5103     0.1086    4.6999   0.0000    0.2975    0.7231\n",
      "1        -0.2741     0.1043   -2.6280   0.0086   -0.4785   -0.0697\n",
      "2         1.1439     0.1084   10.5531   0.0000    0.9314    1.3563\n",
      "3        -0.5601     0.1107   -5.0586   0.0000   -0.7772   -0.3431\n",
      "4         0.3159     0.0943    3.3499   0.0008    0.1311    0.5008\n",
      "5         0.0672     0.0963    0.6978   0.4853   -0.1216    0.2561\n",
      "6        -0.3615     0.0853   -4.2364   0.0000   -0.5288   -0.1943\n",
      "7        -0.4561     0.0900   -5.0661   0.0000   -0.6326   -0.2797\n",
      "8        -0.4244     0.0924   -4.5912   0.0000   -0.6056   -0.2432\n",
      "9        -0.0113     0.1032   -0.1099   0.9125   -0.2136    0.1909\n",
      "10       -0.3590     0.1009   -3.5575   0.0004   -0.5568   -0.1612\n",
      "11        0.0057     0.1029    0.0555   0.9557   -0.1961    0.2075\n",
      "12       -0.1620     0.1003   -1.6146   0.1064   -0.3586    0.0347\n",
      "13       -0.0580     0.0973   -0.5963   0.5509   -0.2487    0.1327\n",
      "14       -0.1511     0.1030   -1.4670   0.1424   -0.3529    0.0508\n",
      "15        0.9976     0.1069    9.3342   0.0000    0.7882    1.2071\n",
      "16       -0.2065     0.0934   -2.2112   0.0270   -0.3896   -0.0235\n",
      "17        0.1473     0.0911    1.6161   0.1061   -0.0313    0.3259\n",
      "18        0.9227     0.0981    9.4092   0.0000    0.7305    1.1149\n",
      "19       -0.3598     0.0819   -4.3911   0.0000   -0.5203   -0.1992\n",
      "20       -0.4591     0.0910   -5.0461   0.0000   -0.6374   -0.2808\n",
      "21        0.0331     0.0891    0.3720   0.7099   -0.1415    0.2077\n",
      "22        0.7048     0.1059    6.6557   0.0000    0.4972    0.9123\n",
      "23       -0.4217     0.1181   -3.5713   0.0004   -0.6531   -0.1903\n",
      "24        0.0796     0.1135    0.7012   0.4832   -0.1428    0.3020\n",
      "25        0.3928     0.0857    4.5829   0.0000    0.2248    0.5607\n",
      "26        0.4134     0.1254    3.2956   0.0010    0.1676    0.6593\n",
      "27        0.3747     0.0903    4.1480   0.0000    0.1977    0.5518\n",
      "28        0.3662     0.1057    3.4656   0.0005    0.1591    0.5732\n",
      "29        0.0267     0.0885    0.3018   0.7628   -0.1467    0.2001\n",
      "30        0.1176     0.1076    1.0929   0.2744   -0.0933    0.3285\n",
      "31        0.8581     0.0931    9.2158   0.0000    0.6756    1.0407\n",
      "32       -0.4123     0.0907   -4.5432   0.0000   -0.5901   -0.2344\n",
      "33       -0.4788     0.0910   -5.2592   0.0000   -0.6573   -0.3004\n",
      "34       -0.7137     0.1008   -7.0794   0.0000   -0.9113   -0.5161\n",
      "35       -1.0093     0.1040   -9.7044   0.0000   -1.2132   -0.8055\n",
      "36        0.2232     0.0998    2.2368   0.0253    0.0276    0.4188\n",
      "37       -0.0600     0.0958   -0.6260   0.5313   -0.2478    0.1278\n",
      "38       -0.3897     0.0877   -4.4427   0.0000   -0.5616   -0.2178\n",
      "39       -0.0185     0.0957   -0.1934   0.8466   -0.2062    0.1691\n",
      "40       -0.3491     0.0722   -4.8342   0.0000   -0.4907   -0.2076\n",
      "41       -0.7073     0.0992   -7.1306   0.0000   -0.9018   -0.5129\n",
      "42       -0.4995     0.0942   -5.3049   0.0000   -0.6841   -0.3150\n",
      "43       -0.0702     0.1034   -0.6784   0.4975   -0.2728    0.1325\n",
      "44       -0.4145     0.0990   -4.1890   0.0000   -0.6085   -0.2206\n",
      "45        0.1906     0.0955    1.9960   0.0459    0.0034    0.3777\n",
      "46        0.2727     0.0995    2.7425   0.0061    0.0778    0.4677\n",
      "47       -0.1380     0.0935   -1.4756   0.1400   -0.3213    0.0453\n",
      "48        0.8058     0.1006    8.0126   0.0000    0.6087    1.0029\n",
      "49        0.3379     0.1018    3.3180   0.0009    0.1383    0.5374\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "Y = data_final.loc[:, data_final.columns == 'y']\n",
    "X = data_final.loc[:, data_final.columns != 'y']\n",
    "\n",
    "logit_model = sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [5, 9, 11, 12, 13, 16, 21, 24, 29,37,39,43,45,47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(X.columns[a], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 36)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.407213\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.413    \n",
      "Dependent Variable: y                AIC:              3745.0591\n",
      "Date:               2020-07-10 12:48 BIC:              3975.9650\n",
      "No. Observations:   4510             Log-Likelihood:   -1836.5  \n",
      "Df Model:           35               LL-Null:          -3126.1  \n",
      "Df Residuals:       4474             LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     7.0000                                      \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0        0.4816     0.0930     5.1761   0.0000    0.2992    0.6639\n",
      "1       -0.3043     0.0972    -3.1305   0.0017   -0.4948   -0.1138\n",
      "2        1.2544     0.1017    12.3294   0.0000    1.0550    1.4538\n",
      "3       -0.5688     0.0994    -5.7248   0.0000   -0.7636   -0.3741\n",
      "4        0.2863     0.0859     3.3331   0.0009    0.1180    0.4547\n",
      "6       -0.4506     0.0783    -5.7549   0.0000   -0.6041   -0.2972\n",
      "7       -0.4381     0.0834    -5.2526   0.0000   -0.6016   -0.2746\n",
      "8       -0.4358     0.0872    -4.9999   0.0000   -0.6066   -0.2650\n",
      "10      -0.3297     0.0900    -3.6629   0.0002   -0.5061   -0.1533\n",
      "14      -0.1116     0.0872    -1.2798   0.2006   -0.2825    0.0593\n",
      "15       0.9979     0.0836    11.9389   0.0000    0.8341    1.1617\n",
      "17       0.2009     0.0841     2.3894   0.0169    0.0361    0.3657\n",
      "18       0.9603     0.0848    11.3296   0.0000    0.7941    1.1264\n",
      "19      -0.4219     0.0723    -5.8327   0.0000   -0.5637   -0.2801\n",
      "20      -0.3914     0.0851    -4.5977   0.0000   -0.5582   -0.2245\n",
      "22       0.6655     0.0927     7.1773   0.0000    0.4838    0.8472\n",
      "23      -0.3377     0.0885    -3.8151   0.0001   -0.5112   -0.1642\n",
      "25       0.4274     0.0818     5.2240   0.0000    0.2671    0.5878\n",
      "26       0.4390     0.1035     4.2425   0.0000    0.2362    0.6418\n",
      "27       0.3911     0.0724     5.4039   0.0000    0.2493    0.5330\n",
      "28       0.3446     0.0950     3.6260   0.0003    0.1583    0.5308\n",
      "30       0.0436     0.0954     0.4570   0.6476   -0.1434    0.2306\n",
      "31       0.8296     0.0845     9.8133   0.0000    0.6639    0.9953\n",
      "32      -0.4310     0.0790    -5.4531   0.0000   -0.5859   -0.2761\n",
      "33      -0.4036     0.0752    -5.3669   0.0000   -0.5510   -0.2562\n",
      "34      -0.6983     0.0933    -7.4845   0.0000   -0.8811   -0.5154\n",
      "35      -1.0343     0.0963   -10.7425   0.0000   -1.2230   -0.8456\n",
      "36       0.2116     0.0843     2.5099   0.0121    0.0464    0.3768\n",
      "38      -0.3230     0.0740    -4.3654   0.0000   -0.4680   -0.1780\n",
      "40      -0.3288     0.0662    -4.9634   0.0000   -0.4586   -0.1990\n",
      "41      -0.6180     0.0872    -7.0890   0.0000   -0.7889   -0.4472\n",
      "42      -0.4512     0.0824    -5.4767   0.0000   -0.6126   -0.2897\n",
      "44      -0.3488     0.0916    -3.8073   0.0001   -0.5283   -0.1692\n",
      "46       0.2560     0.0869     2.9466   0.0032    0.0857    0.4262\n",
      "48       0.8523     0.0912     9.3456   0.0000    0.6736    1.0311\n",
      "49       0.2753     0.0928     2.9674   0.0030    0.0935    0.4571\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [4,9,21,32]\n",
    "X.drop(X.columns[a], axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.409877\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.409    \n",
      "Dependent Variable: y                AIC:              3761.0861\n",
      "Date:               2020-07-10 12:48 BIC:              3966.3358\n",
      "No. Observations:   4510             Log-Likelihood:   -1848.5  \n",
      "Df Model:           31               LL-Null:          -3126.1  \n",
      "Df Residuals:       4478             LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     7.0000                                      \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0        0.4547     0.0902     5.0400   0.0000    0.2779    0.6316\n",
      "1       -0.3068     0.0963    -3.1870   0.0014   -0.4955   -0.1181\n",
      "2        1.1201     0.0933    12.0049   0.0000    0.9372    1.3029\n",
      "3       -0.6807     0.0923    -7.3773   0.0000   -0.8616   -0.4999\n",
      "6       -0.4697     0.0749    -6.2738   0.0000   -0.6164   -0.3229\n",
      "7       -0.4641     0.0812    -5.7181   0.0000   -0.6232   -0.3050\n",
      "8       -0.4113     0.0855    -4.8106   0.0000   -0.5788   -0.2437\n",
      "10      -0.2437     0.0804    -3.0315   0.0024   -0.4012   -0.0861\n",
      "15       0.8415     0.0754    11.1634   0.0000    0.6937    0.9892\n",
      "17       0.2440     0.0829     2.9427   0.0033    0.0815    0.4064\n",
      "18       0.9825     0.0827    11.8827   0.0000    0.8204    1.1446\n",
      "19      -0.4257     0.0716    -5.9484   0.0000   -0.5659   -0.2854\n",
      "20      -0.4689     0.0834    -5.6199   0.0000   -0.6325   -0.3054\n",
      "22       0.6876     0.0914     7.5213   0.0000    0.5084    0.8668\n",
      "23      -0.2177     0.0837    -2.6024   0.0093   -0.3817   -0.0537\n",
      "25       0.4072     0.0791     5.1509   0.0000    0.2523    0.5622\n",
      "26       0.2604     0.0952     2.7359   0.0062    0.0738    0.4469\n",
      "27       0.2689     0.0664     4.0521   0.0001    0.1388    0.3989\n",
      "28       0.3261     0.0928     3.5141   0.0004    0.1442    0.5079\n",
      "31       0.8508     0.0780    10.9064   0.0000    0.6979    1.0037\n",
      "32      -0.4637     0.0751    -6.1708   0.0000   -0.6110   -0.3164\n",
      "33      -0.3548     0.0735    -4.8296   0.0000   -0.4988   -0.2108\n",
      "34      -0.6476     0.0892    -7.2622   0.0000   -0.8224   -0.4728\n",
      "35      -1.0159     0.0945   -10.7493   0.0000   -1.2011   -0.8307\n",
      "36       0.1399     0.0813     1.7193   0.0856   -0.0196    0.2993\n",
      "38      -0.3855     0.0707    -5.4525   0.0000   -0.5240   -0.2469\n",
      "40      -0.3581     0.0642    -5.5776   0.0000   -0.4840   -0.2323\n",
      "41      -0.6421     0.0813    -7.8962   0.0000   -0.8015   -0.4827\n",
      "42      -0.3739     0.0794    -4.7074   0.0000   -0.5296   -0.2183\n",
      "46       0.2829     0.0839     3.3698   0.0008    0.1183    0.4474\n",
      "48       0.7395     0.0874     8.4611   0.0000    0.5682    0.9108\n",
      "49       0.2391     0.0902     2.6513   0.0080    0.0624    0.4159\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 30)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [7,16]\n",
    "X.drop(X.columns[a], axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.412207\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.405    \n",
      "Dependent Variable: y                AIC:              3778.1112\n",
      "Date:               2020-07-10 12:48 BIC:              3970.5327\n",
      "No. Observations:   4510             Log-Likelihood:   -1859.1  \n",
      "Df Model:           29               LL-Null:          -3126.1  \n",
      "Df Residuals:       4480             LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     7.0000                                      \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0        0.3546     0.0857     4.1391   0.0000    0.1867    0.5225\n",
      "1       -0.3827     0.0940    -4.0731   0.0000   -0.5668   -0.1985\n",
      "2        1.0741     0.0885    12.1397   0.0000    0.9007    1.2475\n",
      "3       -0.6353     0.0890    -7.1417   0.0000   -0.8097   -0.4610\n",
      "6       -0.4849     0.0749    -6.4704   0.0000   -0.6318   -0.3380\n",
      "7       -0.4294     0.0781    -5.4981   0.0000   -0.5824   -0.2763\n",
      "8       -0.3209     0.0830    -3.8678   0.0001   -0.4835   -0.1583\n",
      "15       0.8400     0.0753    11.1544   0.0000    0.6924    0.9876\n",
      "17       0.2621     0.0823     3.1847   0.0014    0.1008    0.4235\n",
      "18       0.9336     0.0810    11.5223   0.0000    0.7748    1.0924\n",
      "19      -0.3675     0.0701    -5.2457   0.0000   -0.5049   -0.2302\n",
      "20      -0.4669     0.0833    -5.6036   0.0000   -0.6302   -0.3036\n",
      "22       0.6468     0.0900     7.1842   0.0000    0.4703    0.8232\n",
      "23      -0.1753     0.0824    -2.1265   0.0335   -0.3369   -0.0137\n",
      "25       0.4218     0.0787     5.3633   0.0000    0.2677    0.5760\n",
      "27       0.2735     0.0647     4.2261   0.0000    0.1466    0.4003\n",
      "28       0.2883     0.0920     3.1349   0.0017    0.1081    0.4686\n",
      "31       0.9091     0.0772    11.7735   0.0000    0.7577    1.0604\n",
      "32      -0.4221     0.0727    -5.8059   0.0000   -0.5646   -0.2796\n",
      "33      -0.3367     0.0717    -4.6941   0.0000   -0.4773   -0.1961\n",
      "34      -0.6828     0.0886    -7.7062   0.0000   -0.8565   -0.5091\n",
      "35      -1.0851     0.0923   -11.7541   0.0000   -1.2660   -0.9041\n",
      "36       0.1270     0.0808     1.5712   0.1161   -0.0314    0.2854\n",
      "38      -0.3440     0.0692    -4.9693   0.0000   -0.4797   -0.2083\n",
      "40      -0.3126     0.0626    -4.9916   0.0000   -0.4353   -0.1898\n",
      "41      -0.5960     0.0802    -7.4317   0.0000   -0.7531   -0.4388\n",
      "42      -0.3430     0.0789    -4.3485   0.0000   -0.4977   -0.1884\n",
      "46       0.3338     0.0813     4.1045   0.0000    0.1744    0.4931\n",
      "48       0.6741     0.0857     7.8691   0.0000    0.5062    0.8421\n",
      "49       0.2974     0.0890     3.3417   0.0008    0.1230    0.4718\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4510, 28)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [13, 16]\n",
    "X.drop(X.columns[a], axis = 1, inplace = True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.413759\n",
      "         Iterations 7\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.403    \n",
      "Dependent Variable: y                AIC:              3788.1093\n",
      "Date:               2020-07-10 12:48 BIC:              3967.7028\n",
      "No. Observations:   4510             Log-Likelihood:   -1866.1  \n",
      "Df Model:           27               LL-Null:          -3126.1  \n",
      "Df Residuals:       4482             LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     7.0000                                      \n",
      "------------------------------------------------------------------\n",
      "         Coef.    Std.Err.      z       P>|z|     [0.025    0.975]\n",
      "------------------------------------------------------------------\n",
      "0        0.3081     0.0815     3.7803   0.0002    0.1483    0.4678\n",
      "1       -0.4078     0.0929    -4.3876   0.0000   -0.5900   -0.2256\n",
      "2        1.0003     0.0832    12.0169   0.0000    0.8372    1.1634\n",
      "3       -0.5770     0.0869    -6.6406   0.0000   -0.7473   -0.4067\n",
      "6       -0.4498     0.0737    -6.1045   0.0000   -0.5943   -0.3054\n",
      "7       -0.4141     0.0768    -5.3950   0.0000   -0.5645   -0.2637\n",
      "8       -0.3243     0.0815    -3.9817   0.0001   -0.4840   -0.1647\n",
      "15       0.7875     0.0717    10.9777   0.0000    0.6469    0.9281\n",
      "17       0.2180     0.0804     2.7120   0.0067    0.0604    0.3755\n",
      "18       0.9261     0.0802    11.5541   0.0000    0.7690    1.0832\n",
      "19      -0.4176     0.0686    -6.0870   0.0000   -0.5520   -0.2831\n",
      "20      -0.4119     0.0814    -5.0632   0.0000   -0.5714   -0.2525\n",
      "22       0.7036     0.0886     7.9439   0.0000    0.5300    0.8772\n",
      "25       0.4224     0.0749     5.6384   0.0000    0.2756    0.5693\n",
      "27       0.2577     0.0641     4.0213   0.0001    0.1321    0.3834\n",
      "31       0.9274     0.0765    12.1222   0.0000    0.7774    1.0773\n",
      "32      -0.3805     0.0718    -5.3003   0.0000   -0.5212   -0.2398\n",
      "33      -0.3128     0.0714    -4.3826   0.0000   -0.4528   -0.1729\n",
      "34      -0.6496     0.0876    -7.4188   0.0000   -0.8212   -0.4780\n",
      "35      -1.0662     0.0918   -11.6154   0.0000   -1.2461   -0.8863\n",
      "36       0.0880     0.0797     1.1035   0.2698   -0.0683    0.2442\n",
      "38      -0.3375     0.0688    -4.9079   0.0000   -0.4723   -0.2027\n",
      "40      -0.2935     0.0621    -4.7281   0.0000   -0.4152   -0.1719\n",
      "41      -0.5976     0.0800    -7.4660   0.0000   -0.7545   -0.4407\n",
      "42      -0.4406     0.0737    -5.9801   0.0000   -0.5850   -0.2962\n",
      "46       0.3854     0.0800     4.8155   0.0000    0.2285    0.5423\n",
      "48       0.6775     0.0836     8.1059   0.0000    0.5137    0.8413\n",
      "49       0.1727     0.0823     2.0985   0.0359    0.0114    0.3340\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model = sm.Logit(Y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = X_test_df.iloc[:, [0,1,2,3,6,7,8,15,17,18,19,20,22,25,27,31,32,33,34,35,36,38,40,41,42,46,48,49]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3642, 28)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3642,), (3642, 1))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 479  111]\n",
      " [ 662 2390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.81      0.55       590\n",
      "         1.0       0.96      0.78      0.86      3052\n",
      "\n",
      "    accuracy                           0.79      3642\n",
      "   macro avg       0.69      0.80      0.71      3642\n",
      "weighted avg       0.87      0.79      0.81      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_final.iloc[:, :50]\n",
    "Y_train = data_final.iloc[:, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators =100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate roc auc\n",
    "roc_value = roc_auc_score(Y_test, y_probs)\n",
    "print(roc_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the parameters, best fit randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   53.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                                                           11, 12, 12, 12, 12, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': array([ 10,  13,  17,  21,  25,  29,  33,  37,  41,  44,  48,  52,  56,\n",
       "        60,  64,  68,  72,  75,  79,  83,  87,  91,  95,  99, 103, 106,\n",
       "       110, 114, 118, 122, 126, 130, 134, 137, 141, 145, 149, 153, 157,\n",
       "       161, 165, 168, 172, 176, 180, 184, 188, 192, 196, 200])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=0)\n",
    "\n",
    "# Fit \n",
    "rs.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 83,\n",
       " 'min_samples_split': 2,\n",
       " 'max_leaf_nodes': 38,\n",
       " 'max_features': 0.7,\n",
       " 'max_depth': 6,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8306656374258614\n"
     ]
    }
   ],
   "source": [
    "best_model = rs.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_probs = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_value = roc_auc_score(Y_test, y_probs)\n",
    "print(roc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 453  137]\n",
      " [ 755 2297]]\n",
      "****************************************************************************************************\n",
      "0.7526212319790302 0.9437140509449465\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.77      0.50       590\n",
      "         1.0       0.94      0.75      0.84      3052\n",
      "\n",
      "    accuracy                           0.76      3642\n",
      "   macro avg       0.66      0.76      0.67      3642\n",
      "weighted avg       0.85      0.76      0.78      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vectore machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_final.iloc[:, :50]\n",
    "Y_train = data_final.iloc[:, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
    "clf = SVC(kernel='linear') \n",
    "  \n",
    "# fitting x samples and y classes \n",
    "clf.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 483  107]\n",
      " [ 626 2426]]\n",
      "****************************************************************************************************\n",
      "0.7948885976408913 0.957757599684169\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.82      0.57       590\n",
      "         1.0       0.96      0.79      0.87      3052\n",
      "\n",
      "    accuracy                           0.80      3642\n",
      "   macro avg       0.70      0.81      0.72      3642\n",
      "weighted avg       0.87      0.80      0.82      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_final.iloc[:, :50]\n",
    "Y_train = data_final.iloc[:, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 450  140]\n",
      " [ 808 2244]]\n",
      "****************************************************************************************************\n",
      "0.7352555701179554 0.9412751677852349\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.76      0.49       590\n",
      "         1.0       0.94      0.74      0.83      3052\n",
      "\n",
      "    accuracy                           0.74      3642\n",
      "   macro avg       0.65      0.75      0.66      3642\n",
      "weighted avg       0.85      0.74      0.77      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_final.iloc[:, :50]\n",
    "Y_train = data_final.iloc[:, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal', input_dim = 50))\n",
    "\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam', loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "4510/4510 [==============================] - 1s 248us/step - loss: 0.5937 - accuracy: 0.7295\n",
      "Epoch 2/100\n",
      "4510/4510 [==============================] - 1s 129us/step - loss: 0.4331 - accuracy: 0.7989\n",
      "Epoch 3/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.4195 - accuracy: 0.8111\n",
      "Epoch 4/100\n",
      "4510/4510 [==============================] - 1s 129us/step - loss: 0.4172 - accuracy: 0.8084\n",
      "Epoch 5/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.4129 - accuracy: 0.8142\n",
      "Epoch 6/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.4132 - accuracy: 0.8086\n",
      "Epoch 7/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.4117 - accuracy: 0.8149\n",
      "Epoch 8/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.4101 - accuracy: 0.8160\n",
      "Epoch 9/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.4097 - accuracy: 0.8146\n",
      "Epoch 10/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.4081 - accuracy: 0.8142\n",
      "Epoch 11/100\n",
      "4510/4510 [==============================] - 1s 138us/step - loss: 0.4073 - accuracy: 0.8115\n",
      "Epoch 12/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.4070 - accuracy: 0.8140\n",
      "Epoch 13/100\n",
      "4510/4510 [==============================] - 1s 135us/step - loss: 0.4061 - accuracy: 0.8126\n",
      "Epoch 14/100\n",
      "4510/4510 [==============================] - 1s 135us/step - loss: 0.4053 - accuracy: 0.8140\n",
      "Epoch 15/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.4037 - accuracy: 0.8151\n",
      "Epoch 16/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.4030 - accuracy: 0.8146\n",
      "Epoch 17/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.4005 - accuracy: 0.8175\n",
      "Epoch 18/100\n",
      "4510/4510 [==============================] - 1s 127us/step - loss: 0.4020 - accuracy: 0.8162\n",
      "Epoch 19/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.3997 - accuracy: 0.8197\n",
      "Epoch 20/100\n",
      "4510/4510 [==============================] - 1s 125us/step - loss: 0.3983 - accuracy: 0.8155\n",
      "Epoch 21/100\n",
      "4510/4510 [==============================] - 1s 124us/step - loss: 0.3966 - accuracy: 0.8173\n",
      "Epoch 22/100\n",
      "4510/4510 [==============================] - 1s 129us/step - loss: 0.3964 - accuracy: 0.8171\n",
      "Epoch 23/100\n",
      "4510/4510 [==============================] - 1s 138us/step - loss: 0.3964 - accuracy: 0.8180\n",
      "Epoch 24/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3942 - accuracy: 0.8188\n",
      "Epoch 25/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3939 - accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "4510/4510 [==============================] - 1s 135us/step - loss: 0.3930 - accuracy: 0.8206\n",
      "Epoch 27/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3918 - accuracy: 0.8213\n",
      "Epoch 28/100\n",
      "4510/4510 [==============================] - 1s 137us/step - loss: 0.3909 - accuracy: 0.8213\n",
      "Epoch 29/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3894 - accuracy: 0.8202\n",
      "Epoch 30/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.3885 - accuracy: 0.8231\n",
      "Epoch 31/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3862 - accuracy: 0.8220\n",
      "Epoch 32/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.3858 - accuracy: 0.8224\n",
      "Epoch 33/100\n",
      "4510/4510 [==============================] - 1s 140us/step - loss: 0.3837 - accuracy: 0.8237\n",
      "Epoch 34/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3834 - accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.3812 - accuracy: 0.8233\n",
      "Epoch 36/100\n",
      "4510/4510 [==============================] - 1s 127us/step - loss: 0.3801 - accuracy: 0.8273\n",
      "Epoch 37/100\n",
      "4510/4510 [==============================] - 1s 126us/step - loss: 0.3789 - accuracy: 0.8275\n",
      "Epoch 38/100\n",
      "4510/4510 [==============================] - 1s 126us/step - loss: 0.3777 - accuracy: 0.8273\n",
      "Epoch 39/100\n",
      "4510/4510 [==============================] - 1s 126us/step - loss: 0.3764 - accuracy: 0.8308\n",
      "Epoch 40/100\n",
      "4510/4510 [==============================] - 1s 126us/step - loss: 0.3757 - accuracy: 0.8284\n",
      "Epoch 41/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.3737 - accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3735 - accuracy: 0.8302\n",
      "Epoch 43/100\n",
      "4510/4510 [==============================] - 1s 139us/step - loss: 0.3713 - accuracy: 0.8326\n",
      "Epoch 44/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3710 - accuracy: 0.8304\n",
      "Epoch 45/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.3680 - accuracy: 0.8348\n",
      "Epoch 46/100\n",
      "4510/4510 [==============================] - 0s 104us/step - loss: 0.3686 - accuracy: 0.8328\n",
      "Epoch 47/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3652 - accuracy: 0.8315\n",
      "Epoch 48/100\n",
      "4510/4510 [==============================] - 1s 129us/step - loss: 0.3643 - accuracy: 0.8341\n",
      "Epoch 49/100\n",
      "4510/4510 [==============================] - 1s 125us/step - loss: 0.3642 - accuracy: 0.8341\n",
      "Epoch 50/100\n",
      "4510/4510 [==============================] - 1s 126us/step - loss: 0.3622 - accuracy: 0.8350\n",
      "Epoch 51/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.3595 - accuracy: 0.8361\n",
      "Epoch 52/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3570 - accuracy: 0.8399\n",
      "Epoch 53/100\n",
      "4510/4510 [==============================] - 1s 137us/step - loss: 0.3583 - accuracy: 0.8373\n",
      "Epoch 54/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3559 - accuracy: 0.8399\n",
      "Epoch 55/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3541 - accuracy: 0.8410\n",
      "Epoch 56/100\n",
      "4510/4510 [==============================] - 1s 136us/step - loss: 0.3541 - accuracy: 0.8426\n",
      "Epoch 57/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3525 - accuracy: 0.8432\n",
      "Epoch 58/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3511 - accuracy: 0.8401\n",
      "Epoch 59/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3505 - accuracy: 0.8417\n",
      "Epoch 60/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3498 - accuracy: 0.8415\n",
      "Epoch 61/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3490 - accuracy: 0.8432\n",
      "Epoch 62/100\n",
      "4510/4510 [==============================] - 1s 125us/step - loss: 0.3484 - accuracy: 0.8421\n",
      "Epoch 63/100\n",
      "4510/4510 [==============================] - 1s 137us/step - loss: 0.3463 - accuracy: 0.8408\n",
      "Epoch 64/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3453 - accuracy: 0.8439\n",
      "Epoch 65/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3445 - accuracy: 0.8457\n",
      "Epoch 66/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3429 - accuracy: 0.8483\n",
      "Epoch 67/100\n",
      "4510/4510 [==============================] - 1s 129us/step - loss: 0.3424 - accuracy: 0.8492\n",
      "Epoch 68/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3405 - accuracy: 0.8475\n",
      "Epoch 69/100\n",
      "4510/4510 [==============================] - 1s 138us/step - loss: 0.3387 - accuracy: 0.8519\n",
      "Epoch 70/100\n",
      "4510/4510 [==============================] - 1s 138us/step - loss: 0.3402 - accuracy: 0.8461\n",
      "Epoch 71/100\n",
      "4510/4510 [==============================] - 1s 139us/step - loss: 0.3400 - accuracy: 0.8459\n",
      "Epoch 72/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3369 - accuracy: 0.8461\n",
      "Epoch 73/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3385 - accuracy: 0.8475\n",
      "Epoch 74/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3364 - accuracy: 0.8492\n",
      "Epoch 75/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3358 - accuracy: 0.8532\n",
      "Epoch 76/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3348 - accuracy: 0.8514\n",
      "Epoch 77/100\n",
      "4510/4510 [==============================] - 1s 138us/step - loss: 0.3352 - accuracy: 0.8466\n",
      "Epoch 78/100\n",
      "4510/4510 [==============================] - 1s 129us/step - loss: 0.3362 - accuracy: 0.8490\n",
      "Epoch 79/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3328 - accuracy: 0.8525\n",
      "Epoch 80/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3321 - accuracy: 0.8481\n",
      "Epoch 81/100\n",
      "4510/4510 [==============================] - 1s 128us/step - loss: 0.3315 - accuracy: 0.8523\n",
      "Epoch 82/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3300 - accuracy: 0.8521\n",
      "Epoch 83/100\n",
      "4510/4510 [==============================] - 1s 140us/step - loss: 0.3303 - accuracy: 0.8503\n",
      "Epoch 84/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3309 - accuracy: 0.8523\n",
      "Epoch 85/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3287 - accuracy: 0.8523\n",
      "Epoch 86/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3295 - accuracy: 0.8519\n",
      "Epoch 87/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3267 - accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "4510/4510 [==============================] - 1s 130us/step - loss: 0.3244 - accuracy: 0.8568\n",
      "Epoch 89/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3240 - accuracy: 0.8574\n",
      "Epoch 90/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3251 - accuracy: 0.8552\n",
      "Epoch 91/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3242 - accuracy: 0.8530\n",
      "Epoch 92/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3248 - accuracy: 0.8576\n",
      "Epoch 93/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.3231 - accuracy: 0.8563\n",
      "Epoch 94/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3228 - accuracy: 0.8579\n",
      "Epoch 95/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3209 - accuracy: 0.8592\n",
      "Epoch 96/100\n",
      "4510/4510 [==============================] - 1s 133us/step - loss: 0.3203 - accuracy: 0.8559\n",
      "Epoch 97/100\n",
      "4510/4510 [==============================] - 1s 134us/step - loss: 0.3202 - accuracy: 0.8563\n",
      "Epoch 98/100\n",
      "4510/4510 [==============================] - 1s 132us/step - loss: 0.3193 - accuracy: 0.8594\n",
      "Epoch 99/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.3185 - accuracy: 0.8603\n",
      "Epoch 100/100\n",
      "4510/4510 [==============================] - 1s 131us/step - loss: 0.3167 - accuracy: 0.8612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1dc20aa44c8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train, Y_train, batch_size=16, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4510/4510 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30999099778758976, 0.8645232915878296]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model=classifier.evaluate(X_train, Y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 491   99]\n",
      " [ 707 2345]]\n",
      "****************************************************************************************************\n",
      "0.768348623853211 0.95949263502455\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.83      0.55       590\n",
      "         1.0       0.96      0.77      0.85      3052\n",
      "\n",
      "    accuracy                           0.78      3642\n",
      "   macro avg       0.68      0.80      0.70      3642\n",
      "weighted avg       0.87      0.78      0.80      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_final.iloc[:, :50]\n",
    "Y_train = data_final.iloc[:, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# best is for k = 13 tried with other values but best is k = 13\n",
    "model = KNeighborsClassifier(n_neighbors =15)\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 451  139]\n",
      " [ 903 2149]]\n",
      "****************************************************************************************************\n",
      "0.7041284403669725 0.9392482517482518\n",
      "****************************************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.76      0.46       590\n",
      "         1.0       0.94      0.70      0.80      3052\n",
      "\n",
      "    accuracy                           0.71      3642\n",
      "   macro avg       0.64      0.73      0.63      3642\n",
      "weighted avg       0.84      0.71      0.75      3642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(Y_test, y_pred)\n",
    "print(conf_mat)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "precision = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[1,0])\n",
    "recall = conf_mat[1,1] / (conf_mat[1,1] + conf_mat[0,1])\n",
    "print(precision, recall)\n",
    "\n",
    "print('*'*100)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
